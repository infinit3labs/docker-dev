# Enable Delta Lake and set a local V2 catalog named "local"
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension

# Register a named catalog (top-level) so three-part names work: local.<schema>.<table>
spark.sql.catalog.local=org.apache.spark.sql.delta.catalog.V2TableCatalog

# Point the catalog to a warehouse dir (overridable via UC_WAREHOUSE env)
spark.sql.catalog.local.warehouse=file:///workspace/warehouse

# Make the named catalog the default, so "schema.table" resolves to "local.schema.table"
spark.sql.defaultCatalog=local

# Reasonable local defaults
spark.driver.bindAddress=0.0.0.0
spark.sql.session.timeZone=UTC
spark.ui.enabled=false
